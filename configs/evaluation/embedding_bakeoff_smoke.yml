# Phase 3c Embedding Bake-Off smoke configuration
experiment:
  name: "phase3c_embedding_bakeoff_smoke"
  output_dir: "results/embedding_bakeoff_smoke"
  per_run_metrics_file: "per_run_metrics.jsonl"
  summary_file: "summary_metrics.json"
  detailed_results_dir: "runs"

dataset:
  queries_path: "data/evaluation/gold/queries.jsonl"
  answers_path: "data/evaluation/gold/answers.jsonl"
  qrels_path: "data/evaluation/gold/qrels.tsv"
  document_source:
    markdown_dir: "docs/google_sites_guide"
    servicenow_jsonl: "docs/servicenow/task_prepared.jsonl"

runtime:
  max_queries: 3
  persist_responses: true

frozen:
  generator:
    provider: "llama_cpp"
    llm_name: "Qwen2.5-14B-Instruct"
    temperature: 0.0
    max_new_tokens: 128
  index:
    type: "faiss"
    metric: "cosine"
  metrics:
    retrieval_k: 10

sweeps:
  embedding_models:
    - name: "bge-small-en-v1.5"
      source: "registry"
  chunk_size: [256]
  chunk_overlap: [32]
  top_k: [10]

judge:
  provider: "llama_cpp"
  llm_name: "Qwen2.5-14B-Instruct"
  prompt: |
    You are an expert RAG evaluator. Assess whether the generated answer is supported by the retrieved context.
    Score faithfulness on a scale of 1 (hallucinated) to 5 (fully grounded in the context).
    Provide a JSON object with keys "score" (integer 1-5) and "justification" (short explanation).

  faithfulness_threshold: 4
  hallucination_threshold: 2
