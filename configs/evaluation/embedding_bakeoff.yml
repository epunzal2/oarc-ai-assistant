# Phase 3c Embedding Bake-Off configuration
experiment:
  name: "phase3c_embedding_bakeoff"
  output_dir: "results/embedding_bakeoff"
  per_run_metrics_file: "per_run_metrics.jsonl"
  summary_file: "summary_metrics.json"
  detailed_results_dir: "runs"

dataset:
  queries_path: "data/evaluation/gold/queries.jsonl"
  answers_path: "data/evaluation/gold/answers.jsonl"
  qrels_path: "data/evaluation/gold/qrels.tsv"
  document_source:
    markdown_dir: "docs/google_sites_guide"
    # Align with qrels which reference markdown docs; exclude ServiceNow for this eval
    servicenow_jsonl: null

frozen:
  generator:
    provider: "llama_cpp"
    llm_name: "Qwen2.5-14B-Instruct"
    temperature: 0.0
    max_new_tokens: 256
    # Force a simple ChatML-style template without tool-calling branches
    chat_template: "configs/chat_templates/qwen_chatml_no_tools.jinja"
  index:
    type: "faiss"
    metric: "cosine"
  metrics:
    retrieval_k: 10

sweeps:
  embedding_models:
    - name: "sentence-transformers/all-MiniLM-L6-v2"
      source: "huggingface"
      langchain_class: "HuggingFaceEmbeddings"
    - name: "bge-small-en-v1.5"
      source: "registry"
    - name: "bge-large-en-v1.5"
      source: "registry"
    - name: "gte-large-en-v1.5"
      source: "registry"
  chunk_size: [256, 320]
  chunk_overlap: [32, 48]
  top_k: [10, 20]

judge:
  provider: "llama_cpp"
  llm_name: "Qwen2.5-14B-Instruct"
  # Keep judge on the same simple template for consistency
  chat_template: "configs/chat_templates/qwen_chatml_no_tools.jinja"
  prompt: |
    You are an expert RAG evaluator. Assess whether the generated answer is supported by the retrieved context.
    Score faithfulness on a scale of 1 (hallucinated) to 5 (fully grounded in the context).
    Return ONLY a JSON object with the following exact shape and no extra text:
    {"score": <integer 1-5>, "justification": "<one short sentence>"}

  faithfulness_threshold: 4
  hallucination_threshold: 2
